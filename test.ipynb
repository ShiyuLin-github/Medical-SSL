{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchio.transforms\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob\n",
    "import SimpleITK as sitk\n",
    "from scipy import ndimage\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from scipy.special import comb\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试cuda\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看permutations文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_permutations_path = r'datasets_3D\\Rubik_cube\\permutaions\\permutations_hamming_max_100.npy'\n",
    "K_permutations = np.load(k_permutations_path)\n",
    "#可以用vscode自带的数据查看器查看"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试np.flip产生的错误step must be greater than zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, 10)\n",
    "# x[:, ::-1]\n",
    "# > ValueError: step must be greater than zero\n",
    "x.numpy()[:, ::-1] # works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = np.random.randn(10, 10)\n",
    "a.strides\n",
    "# > (80, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.flip(a)\n",
    "a.strides\n",
    "# > (-80, -8) strides的涵义我收藏了一篇文章可以翻阅\n",
    "\n",
    "x = torch.from_numpy(a)\n",
    "# > ValueError: At least one stride in the given numpy array is negative, and tensors with negative strides are not currently supported. (You can probably work around this by making a copy of your array  with array.copy().) \n",
    "\n",
    "x = torch.from_numpy(a.copy()) # works\n",
    "x.stride()\n",
    "# > (10, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试MRI_rkb_plus_pretask中的get_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试全代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置假设input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.rand(240,240,155)\n",
    "print(t1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置假设config参数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = [120, 120, 77]\n",
    "flag = 'train'\n",
    "num_grids_per_axis = 2\n",
    "num_cubes = num_grids_per_axis ** 3\n",
    "print(num_cubes)\n",
    "k_permutations_path = r'datasets_3D\\Rubik_cube\\permutaions\\permutations_hamming_max_100.npy'\n",
    "K_permutations = np.load(k_permutations_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def会用到的一些函数（from base_rkb_pretask）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_3d(image, flag, crop_size): # ...（对图像执行3D裁剪的方法）\n",
    "    h, w, d = crop_size[0], crop_size[1], crop_size[2]\n",
    "    h_old, w_old, d_old = image.shape[0], image.shape[1], image.shape[2]\n",
    "\n",
    "    if flag == 'train': #如果 flag 是 'train'，则进行随机裁剪。在这种情况下，生成随机的裁剪起始点 (x, y, z)，h_old-h是为了确保裁剪框不超出图像边界。\n",
    "        # crop random\n",
    "        x = np.random.randint(0, 1 + h_old - h) #返回一个随机数或随机数数组(指定size时)\n",
    "        y = np.random.randint(0, 1 + w_old - w)\n",
    "        z = np.random.randint(0, 1 + d_old - d)\n",
    "    else: #如果 flag 不是 'train'，则进行中心裁剪。计算裁剪起始点 (x, y, z) 使得裁剪的区域在图像中居中。\n",
    "        # crop center\n",
    "        x = int((h_old - h) / 2)\n",
    "        y = int((w_old - w) / 2)\n",
    "        z = int((d_old - d) / 2)\n",
    "\n",
    "    return do_crop_3d(image, x, y, z, h, w, d)\n",
    "\n",
    "def do_crop_3d(image, x, y, z, h, w, d): #3D裁剪的辅助函数，确保整数和返回对应位置的3D块\n",
    "    assert type(x) == int, x\n",
    "    assert type(y) == int, y\n",
    "    assert type(z) == int, z\n",
    "    assert type(h) == int, h\n",
    "    assert type(w) == int, w\n",
    "    assert type(d) == int, d\n",
    "\n",
    "    return image[x:x + h, y:y + w, z:z + d] #这边取的时最边界点加上crop_size的大小，解释了为何上述代码的定中心方式如此\n",
    "\n",
    "def crop_cubes_3d(image, flag, cubes_per_side, cube_jitter_xy=3, cube_jitter_z=3): #在3D图像中裁剪多个3D立方体的方法，jitter貌似是为了防止数据连续变化留出的间隔大小，从代码里可以看出如果有jitter则再次进行3D裁切，cubes_per_side应该是每个方向有多少个cube\n",
    "    h, w, d = image.shape\n",
    "\n",
    "    patch_overlap = -cube_jitter_xy if cube_jitter_xy < 0 else 0 #patch_overlap 计算了在裁剪时可能存在的重叠区域。如果 cube_jitter_xy 是负数，则 patch_overlap 采用该值；否则，为零。\n",
    "\n",
    "    #h_grid、w_grid 和 d_grid 计算了每个立方体的网格大小，以确保裁剪时没有重叠区域。\n",
    "    # 这里主要思想应该是把切出来的3D大块划分为各个小块,这里拿笔记做做数学题吧，好久没写了。\n",
    "    h_grid = (h - patch_overlap) // cubes_per_side\n",
    "    w_grid = (w - patch_overlap) // cubes_per_side\n",
    "    d_grid = (d - patch_overlap) // cubes_per_side\n",
    "    h_patch = h_grid - cube_jitter_xy\n",
    "    w_patch = w_grid - cube_jitter_xy\n",
    "    d_patch = d_grid - cube_jitter_z\n",
    "\n",
    "    cubes = []\n",
    "    for i in range(cubes_per_side):\n",
    "        for j in range(cubes_per_side):\n",
    "            for k in range(cubes_per_side):\n",
    "\n",
    "                p = do_crop_3d(image, #当i=0时，从0截取到第一个grid\n",
    "                                i * h_grid,\n",
    "                                j * w_grid,\n",
    "                                k * d_grid,\n",
    "                                h_grid + patch_overlap,\n",
    "                                w_grid + patch_overlap,\n",
    "                                d_grid + patch_overlap)\n",
    "\n",
    "                if h_patch < h_grid or w_patch < w_grid or d_patch < d_grid: #如果有jitter，则对之前裁切好的3D块再次裁切以保留jitter大小的间隔\n",
    "                    p = crop_3d(p, flag, [h_patch, w_patch, d_patch])\n",
    "\n",
    "                cubes.append(p)\n",
    "\n",
    "    return cubes\n",
    "\n",
    "def rearrange(cubes, K_permutations):  # ...根据排列重新排列立方体的方法\n",
    "    label = random.randint(0, len(K_permutations) - 1)\n",
    "    print('label', np.array(K_permutations[label]), label)\n",
    "    return np.array(cubes)[np.array(K_permutations[label])], label\n",
    "\n",
    "def center_crop_xy(image, size): # 在image中间截一个size大小的缺口，画图很容易理解\n",
    "    \"\"\"CenterCrop a sample.\n",
    "        Args:\n",
    "            image: [D, H, W]\n",
    "            label:[D, H, W]\n",
    "            crop_size: the desired output size in the x-y plane\n",
    "        Returns:\n",
    "            out_image:[D, h, w]\n",
    "            out_label:[D, h, w]\n",
    "    \"\"\"\n",
    "    h, w, d = image.shape\n",
    "\n",
    "    h1 = int(round((h - size[0]) / 2.)) #round() 函数将结果四舍五入为最接近的整数，确保裁剪区域的起始点是整数。\n",
    "    w1 = int(round((w - size[1]) / 2.))\n",
    "\n",
    "    image = image[h1:h1 + size[0], w1:w1 + size[1], :]\n",
    "    return image\n",
    "\n",
    "def rotate(cubes): # ...（旋转3D立方体的方法）\n",
    "\n",
    "    # multi-hot labels\n",
    "    # [8, H, W, D]\n",
    "    rot_cubes = copy.deepcopy(cubes) # 创建输入立方体的深层副本，以免修改原始数据\n",
    "    hor_vector = [] # 记录水平旋转的向量\n",
    "    ver_vector = [] # 记录垂直旋转的向量\n",
    "\n",
    "    for i in range(num_cubes):\n",
    "        p = random.random()  # 生成一个0到1之间的随机数\n",
    "        cube = rot_cubes[i] # 获取当前处理的立方体,这里debug看cube是个tensor，后续会出bug\n",
    "        cube_ = cube.numpy() #设置一个numpy_arrary防止np.flip bug\n",
    "        # p = 0.1 # for test\n",
    "        # [H, W, D]\n",
    "        if p < 1/3: # 如果 p 小于 1/3，表示进行水平旋转。将水平旋转的标志添加到 hor_vector，并沿x轴翻转180度。\n",
    "            hor_vector.append(1)\n",
    "            ver_vector.append(0)\n",
    "            # rotate 180 along x axis\n",
    "            # rot_cubes[i] = np.flip(cube, (1, 2)) # 沿x轴翻转180度,BUG ValueError: step must be greater than zero,最后输出的应该是numpy形式\n",
    "            cube = np.flip(cube_, (1, 2))\n",
    "            rot_cubes[i] = cube\n",
    "        elif p < 2/3: #如果 p 大于等于 1/3 且小于 2/3，表示进行垂直旋转。将垂直旋转的标志添加到 ver_vector，并沿z轴翻转180度。\n",
    "            hor_vector.append(0)\n",
    "            ver_vector.append(1)\n",
    "            # rotate 180 along z axis\n",
    "            # rot_cubes[i] = np.flip(cube, (0, 1)) # 沿z轴翻转180度\n",
    "            cube = np.flip(cube_, (0, 1))\n",
    "            rot_cubes[i] = cube\n",
    "\n",
    "        else: #如果 p 大于等于 2/3，不进行旋转，标志都设为0。\n",
    "            hor_vector.append(0)\n",
    "            ver_vector.append(0)\n",
    "\n",
    "    return rot_cubes, hor_vector, ver_vector\n",
    "\n",
    "def mask(cubes): # ...（对3D立方体应用掩码的方法）\n",
    "    mask_vector = []\n",
    "    masked_cubes = copy.deepcopy(cubes) # 创建一个输入立方体的深层副本，以免修改原始数据\n",
    "    for i in range(num_cubes):\n",
    "        cube = masked_cubes[i] # 获取当前处理的立方体\n",
    "        if random.random() < 0.5: # 如果随机数小于0.5，应用掩码\n",
    "            # mask\n",
    "            mask_vector.append(1) # 记录掩码的标志为1\n",
    "            R = np.random.uniform(0, 1, cube.shape) # 生成与立方体相同形状的随机数矩阵\n",
    "            R = (R > 0.5).astype(np.int32) # 将大于0.5的值设置为1，否则为0，形成二值掩码\n",
    "            masked_cubes[i] = cube * R # 将立方体与二值掩码相乘，进行掩码操作\n",
    "        else:\n",
    "            mask_vector.append(0) # 如果随机数大于等于0.5，不应用掩码，标志为0\n",
    "\n",
    "    return masked_cubes, mask_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试代码主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.Tensor(t1)\n",
    "# input: [240, 240, 155]\n",
    "        \n",
    "input = input_tensor[:,:,0:154]\n",
    "# 截去最后一层方便分块整除\n",
    "\n",
    "if crop_size == [128, 128, 32]:\n",
    "    # input: [276, 276, 74]\n",
    "    input = center_crop_xy(input, [276, 276])\n",
    "\n",
    "    # get all the num_grids **3 cubes\n",
    "    all_cubes = crop_cubes_3d(\n",
    "        input,\n",
    "        flag=flag,\n",
    "        cubes_per_side=num_grids_per_axis,\n",
    "        cube_jitter_xy=10,\n",
    "        cube_jitter_z=5,\n",
    "    )\n",
    "    print(len(all_cubes), all_cubes[0].shape)\n",
    "\n",
    "# 这部分添加适合MRI的块大小\n",
    "# MRI数据集大小[240,240,155],为了能够整除，应该截成154的depth，设crop_size=[120，120，77],之所以做的是整除原因在于抄的上面的代码也是整除\n",
    "elif crop_size == [120, 120, 77]:\n",
    "    # input: [276, 276, 74]\n",
    "    # input = center_crop_xy(input, [276, 276])\n",
    "\n",
    "    # get all the num_grids **3 cubes\n",
    "    all_cubes = crop_cubes_3d(\n",
    "        input,\n",
    "        flag=flag,\n",
    "        cubes_per_side=num_grids_per_axis,\n",
    "        cube_jitter_xy=10,\n",
    "        cube_jitter_z=5,\n",
    "    )\n",
    "    print(len(all_cubes), all_cubes[0].shape)\n",
    "\n",
    "elif crop_size == [64, 64, 16]:\n",
    "    # input: [140, 140, 40]\n",
    "    input = ndimage.zoom(input, [140 / 320, 140 / 320, 40 / 74], order=3)\n",
    "\n",
    "    # get all the num_grids **3 cubes\n",
    "    all_cubes = crop_cubes_3d(\n",
    "        input,\n",
    "        flag=flag,\n",
    "        cubes_per_side=num_grids_per_axis,\n",
    "        cube_jitter_xy=6,\n",
    "        cube_jitter_z=4,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    NotImplementedError(\"This crop size has not been configured yet\")\n",
    "    all_cubes = None\n",
    "\n",
    "# 这里all_cubes还是list形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task1: Permutate the order of cubes\n",
    "rearranged_cubes, order_label = rearrange(all_cubes, K_permutations)\n",
    "\n",
    "print(rearranged_cubes.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task2: Rotate each cube randomly.\n",
    "rotated_cubes, hor_label, ver_label = rotate(rearranged_cubes)\n",
    "\n",
    "# Task2: Mask each cube randomly.\n",
    "masked_cubes, mask_label = mask(rotated_cubes)\n",
    "\n",
    "print(rotated_cubes.shape) # (8,)\n",
    "print(rotated_cubes[0].shape) # torch.Size([110, 110, 72])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_cubes = np.expand_dims(np.array(masked_cubes), axis=1) #在a xis=1的位置增加一个维度，可参文章\n",
    "final_cubes = masked_cubes.tolist() # 转为list方便转换为tensor\n",
    "final_cubes_tensors = torch.stack(torch.from_numpy(final_cubes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(final_cubes.shape) # (8, 1)\n",
    "print(final_cubes[0].shape) # (1,)\n",
    "print(final_cubes[0][0].shape) # torch.Size([110, 110, 72])\n",
    "print(final_cubes_tensors.shape) # (8, 1)\n",
    "print(final_cubes_tensors[0].shape) # (1,)\n",
    "print(final_cubes_tensors[0][0].shape) # torch.Size([110, 110, 72])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cubes_tensors = torch.stack(cubes)\n",
    "print(final_cubes_tensors.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cubes_list = final_cubes.tolist()\n",
    "final_cubes_tensors = torch.stack(final_cubes_list)\n",
    "print(final_cubes_tensors.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "return的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是4个要输出的值\n",
    "print(torch.from_numpy(final_cubes.astype(np.float32)))\n",
    "print(torch.from_numpy(np.array(order_label)))\n",
    "print(torch.from_numpy(np.array(hor_label)).float())\n",
    "print(torch.from_numpy(np.array(ver_label)).float())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试rearrange函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "问题在rearrange函数，进行调试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "torch.Size([110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "# 创建包含8个随机张量的张量\n",
    "num_tensors = 8\n",
    "tensor_size = [110, 110, 72]\n",
    "\n",
    "random_tensors = [torch.rand(tensor_size) for _ in range(num_tensors)]\n",
    "# tensor_arry = np.array(random_tensors) # 源代码中输入的就是list，不需要转为nparrary\n",
    "\n",
    "\n",
    "# 打印结果\n",
    "print(len(random_tensors))\n",
    "print(random_tensors[0].shape) # (1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes = random_tensors\n",
    "cubes_tensor = torch.stack(cubes) # 将嵌套list转为tensor增加测试\n",
    "k_permutations_path = r'datasets_3D\\Rubik_cube\\permutaions\\permutations_hamming_max_100.npy'\n",
    "K_permutations = np.load(k_permutations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = random.randint(0, len(K_permutations) - 1)\n",
    "label = 50 # 设置个label方便debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 0 1 5 6 7 4]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "choosed_permutation = K_permutations[label] # 这里挑出来是nparray类型\n",
    "print(choosed_permutation)\n",
    "print(len(choosed_permutation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试tensor排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearrange_cubes_tensor = cubes_tensor[choosed_permutation]\n",
    "# 检查是否相等\n",
    "are_close = torch.allclose(rearrange_cubes_tensor[2], cubes_tensor[0])\n",
    "print(are_close)\n",
    "are_close = torch.allclose(rearrange_cubes_tensor[1], cubes_tensor[0])\n",
    "print(are_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "d:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "cubes_array = np.array(cubes) # 这句报警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_rearrange =cubes_array[np.array(K_permutations[label])] # 貌似用nparray操作最合适不会报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_tensor = torch.tensor(cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cubes_rearrange =cubes[np.array(K_permutations[label])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label', np.array(K_permutations[label]), label)\n",
    "return np.array(cubes)[np.array(K_permutations[label])], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 嵌套列表\n",
    "nested_list = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "\n",
    "# 将嵌套列表转换为 PyTorch 张量\n",
    "nested_tensor = torch.tensor(nested_list)\n",
    "\n",
    "# 打印结果\n",
    "print(nested_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试VIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vit_pytorch.vit_3d import ViT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = ViT(\n",
    "    image_size = 128,          # image size\n",
    "    frames = 16,               # number of frames\n",
    "    image_patch_size = 16,     # image patch size\n",
    "    frame_patch_size = 2,      # frame patch size\n",
    "    num_classes = 1000,\n",
    "    dim = 1024,\n",
    "    depth = 6,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1\n",
    ")\n",
    "\n",
    "video = torch.randn(4, 3, 16, 128, 128) # (batch, channels, frames, height, width)\n",
    "\n",
    "preds = v(video) # (4, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir: ../checkpoints/MRI/VIT_3d_Simple_RKBPlus_240_240_155_MRI/20231205-220837\n",
      "RUNDIR: ../checkpoints/MRI/VIT_3d_Simple_RKBPlus_240_240_155_MRI/20231205-220837\n",
      "12/05 10:08:37 PM Simple-Train\n",
      "12/05 10:08:37 PM \n",
      "Configurations:\n",
      "12/05 10:08:37 PM attr                           class\n",
      "12/05 10:08:37 PM benchmark                      False\n",
      "12/05 10:08:37 PM epochs                         1000\n",
      "12/05 10:08:37 PM eval_dataset                   MRI\n",
      "12/05 10:08:37 PM gaps                           [6, 6, 4]\n",
      "12/05 10:08:37 PM gpu_ids                        [0]\n",
      "12/05 10:08:37 PM hu_max                         1000.0\n",
      "12/05 10:08:37 PM hu_min                         -1000.0\n",
      "12/05 10:08:37 PM im_channel                     1\n",
      "12/05 10:08:37 PM init_weight_type               kaiming\n",
      "12/05 10:08:37 PM input_size                     [120, 120, 77]\n",
      "12/05 10:08:37 PM k_permutations_path            datasets_3D\\Rubik_cube\\permutaions\\permutations_hamming_max_100.npy\n",
      "12/05 10:08:37 PM learning_rate_decay            [250]\n",
      "12/05 10:08:37 PM loss                           ce\n",
      "12/05 10:08:37 PM lr                             0.001\n",
      "12/05 10:08:37 PM manualseed                     666\n",
      "12/05 10:08:37 PM max_queue_size                 4\n",
      "12/05 10:08:37 PM model                          Simple\n",
      "12/05 10:08:37 PM network                        VIT_3d\n",
      "12/05 10:08:37 PM note                           RKBPlus_240_240_155_MRI\n",
      "12/05 10:08:37 PM num_grids_per_axis             2\n",
      "12/05 10:08:37 PM num_workers                    1\n",
      "12/05 10:08:37 PM optimizer                      adam\n",
      "12/05 10:08:37 PM order_class_num                100\n",
      "12/05 10:08:37 PM org_data_size                  [240, 240, 154]\n",
      "12/05 10:08:37 PM patience                       40\n",
      "12/05 10:08:37 PM pretrained_model               None\n",
      "12/05 10:08:37 PM resume                         None\n",
      "12/05 10:08:37 PM save_model_freq                50\n",
      "12/05 10:08:37 PM scale                          4\n",
      "12/05 10:08:37 PM scheduler                      StepLR_multi_step\n",
      "12/05 10:08:37 PM test_fold                      [7, 8, 9]\n",
      "12/05 10:08:37 PM train_batch                    2\n",
      "12/05 10:08:37 PM train_dataset                  MRI\n",
      "12/05 10:08:37 PM train_fold                     [0, 1, 2, 3, 4]\n",
      "12/05 10:08:37 PM val_batch                      2\n",
      "12/05 10:08:37 PM valid_fold                     [5, 6]\n",
      "12/05 10:08:37 PM \n",
      "\n",
      "******Building training dataloder******\n",
      "******Building test dataloder******\n",
      "initialize network with kaiming\n",
      "12/05 10:08:38 PM use: 1 gpus\n",
      "12/05 10:08:38 PM Training phase : from_scratch\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "from trainers import *\n",
    "import argparse\n",
    "\n",
    "\n",
    "class rkbp_config:\n",
    "\n",
    "    attr = 'class'\n",
    "    # gpu_ids = [0, 1]\n",
    "    gpu_ids = [0] #没有多块GPU，做个修改看能不能跑通\n",
    "    benchmark = False #用于设置cudnn.benchmark\n",
    "    manualseed = 666 #随机数种子\n",
    "    model = 'Simple' #用于决定是否是复杂的模型，在源码中BROL和PCRL是复杂模型\n",
    "    # network = 'unet_3d_rkbp' #用于base_trainer中init_model中的get_networks\n",
    "    network = 'VIT_3d'\n",
    "    init_weight_type = 'kaiming'\n",
    "    note = \"RKBPlus_240_240_155_MRI\" #修改标记\n",
    "\n",
    "    # data\n",
    "    train_fold = [0, 1, 2, 3, 4] #rkb_plus_pretask.py中定义的get_luna_list中用到\n",
    "    valid_fold = [5, 6]\n",
    "    test_fold = [7, 8, 9]\n",
    "    hu_min = -1000.0\n",
    "    hu_max = 1000.0\n",
    "    scale = 4\n",
    "    input_size = [120, 120, 77] # 自己设置的适合切MRI尺寸的大小 # [64, 64, 16]  # [128, 128, 64]\n",
    "    org_data_size = [240, 240, 155-1] #[320, 320, 74]\n",
    "    train_dataset = 'MRI' #用于init_dataloader的get_dataloder_3D\n",
    "    eval_dataset = 'MRI'\n",
    "    im_channel = 1 #用于init_model中的get_networks\n",
    "    order_class_num = 100 #这里的num之所以是100是因为最后要设置分类头对应排序的种数，如果8的阶乘全部用上就太大了，所以挑了个最大数\n",
    "    k_permutations_path = r'datasets_3D\\Rubik_cube\\permutaions\\permutations_hamming_max_100.npy'\n",
    "    #k_permutation在Rubik_cube中的base_rkb_pretask中进行处理，里面存的是所有可能的排列组合顺序和对应标签顺序，比如[1,2,3,4...,6,7,8]为第0种顺序，1 到 8 的数字的排列方式有 40,320 种（8的阶乘）所以文件里存的应该是对应的最大100种，和最大1000种，可以调用出来看一下就知道了\n",
    "    gaps = [6, 6, 4]\n",
    "    num_grids_per_axis = 2\n",
    "\n",
    "    # model pre-training\n",
    "    train_batch = 2 #用于init_dataloader的get_dataloder_3D\n",
    "    val_batch = 2\n",
    "    optimizer = \"adam\"\n",
    "    scheduler = 'StepLR_multi_step'\n",
    "    learning_rate_decay = [250]#[200]\n",
    "    num_workers = 1 #用于init_dataloader的get_dataloder_3D\n",
    "    max_queue_size = num_workers * 4\n",
    "    epochs = 1000\n",
    "    save_model_freq = 50\n",
    "    patience = 40\n",
    "    lr = 1e-3\n",
    "    loss = 'ce' #用于设定loss\n",
    "\n",
    "    # logs\n",
    "    resume = None #继续训练之前训练过的模型\n",
    "    pretrained_model = None #用于trainer中的get_training_phase函数\n",
    "\n",
    "    def display(self, logger):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        logger.info(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)) and not '_idx' in a:\n",
    "                logger.info(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        logger.info(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "config = rkbp_config()\n",
    "Trainer = RKBPTrainer(config)\n",
    "# Trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Trainer.train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "# final_cubes\n",
    "print(test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "tensor(19, dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# order_label\n",
    "print(test[1].shape)\n",
    "print(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([1., 0., 0., 0., 0., 0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "# hor_label\n",
    "print(test[2].shape)\n",
    "print(test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([0., 0., 1., 1., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# ver_label\n",
    "print(test[3].shape)\n",
    "print(test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([1., 0., 1., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# mask_label\n",
    "print(test[4].shape)\n",
    "print(test[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unet3d到VIT3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试Vit作为encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vit_pytorch.vit_3d import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ViT(\n",
    "    image_size = 128,          # image size\n",
    "    frames = 16,               # number of frames\n",
    "    image_patch_size = 16,     # image patch size\n",
    "    frame_patch_size = 2,      # frame patch size\n",
    "    num_classes = 100,\n",
    "    dim = 1024,\n",
    "    depth = 2,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    channels = 1\n",
    ")\n",
    "\n",
    "video = torch.randn(4, 1, 16, 128, 128) # (batch, channels, frames, height, width)\n",
    "\n",
    "preds = v(video) # (4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "\n",
    "# SSL部分dataset排列为B,C,X,Y,Z 进入之前需要重排一下顺序\n",
    "\n",
    "# dataset读取的顺序如下\n",
    "video = torch.randn(4, 1, 240, 240, 155) # (batch, channels, height, width, frames)\n",
    "\n",
    "video_cut = torch.randn(4, 1, 110, 110, 72) # (batch, channels, height, width, frames)\n",
    "\n",
    "print(video_cut.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 72, 110, 110])\n"
     ]
    }
   ],
   "source": [
    "video_cut = rearrange(video_cut, 'b c h w f -> b c f h w')\n",
    "# 这里rearrange和Rearrange效果不一样，大写的是类可参vit_3d里的用法\n",
    "\n",
    "print(video_cut.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "v = ViT(\n",
    "    image_size = 110,          # image size\n",
    "    frames = 72,               # number of frames\n",
    "    image_patch_size = 110,     # image patch size\n",
    "    frame_patch_size = 1,      # frame patch size\n",
    "    num_classes = 64,\n",
    "    dim = 1024,\n",
    "    depth = 1,\n",
    "    heads = 8,\n",
    "    mlp_dim = 2048,\n",
    "    dropout = 0.1,\n",
    "    emb_dropout = 0.1,\n",
    "    channels = 1\n",
    ")\n",
    "\n",
    "preds = v(video_cut)\n",
    "\n",
    "print(preds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 修改unet3d为vit3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64])\n"
     ]
    }
   ],
   "source": [
    "from networks.unet3d import UNet3D_RKBP\n",
    "\n",
    "# 测试output_fc6 = self.forward_once(cubes[i])，cubes[i] = b,1,72,110,110\n",
    "\n",
    "# 创建类的实例\n",
    "my_instance = UNet3D_RKBP()\n",
    "\n",
    "b=2\n",
    "data = torch.randn([b,1,72,110,110])\n",
    "\n",
    "output_fc6 = my_instance.forward_once(data)\n",
    "print(output_fc6.shape) # [2, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 修改草稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_pytorch.vit_3d import ViT\n",
    "from einops import rearrange\n",
    "\n",
    "class VIT3D_RKBP(nn.Module):\n",
    "    # the number of convolutions in each layer corresponds\n",
    "    # to what is in the actual prototxt, not the intent\n",
    "    def __init__(self, in_channels=1, order_n_class=100, num_cubes=8, act='relu'):\n",
    "        super(VIT3D_RKBP, self).__init__()\n",
    "        \n",
    "        self.vit_encoder64 = ViT(\n",
    "                image_size = 110,          # image size\n",
    "                frames = 72,               # number of frames\n",
    "                image_patch_size = 110,     # image patch size\n",
    "                frame_patch_size = 1,      # frame patch size\n",
    "                num_classes = 64,          # encoded dimension\n",
    "                dim = 1024,\n",
    "                depth = 2,\n",
    "                heads = 8,\n",
    "                mlp_dim = 2048,\n",
    "                dropout = 0.1,\n",
    "                emb_dropout = 0.1,\n",
    "                channels = in_channels)\n",
    "        # self.encoder = UNet3D_Encoder(in_channels=in_channels, act=act)\n",
    "        self.gap = torch.nn.AdaptiveAvgPool3d(1)\n",
    "\n",
    "\n",
    "        self.fc6 = nn.Sequential(\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(64),\n",
    "        )\n",
    "\n",
    "        self.order_fc = nn.Sequential(\n",
    "            nn.Linear(num_cubes * 64, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, order_n_class)\n",
    "        )\n",
    "\n",
    "        self.ver_rot_fc = nn.Sequential(\n",
    "            nn.Linear(num_cubes * 64, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_cubes))\n",
    "\n",
    "        self.hor_rot_fc = nn.Sequential(\n",
    "            nn.Linear(num_cubes * 64, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_cubes))\n",
    "\n",
    "        self.mask_fc = nn.Sequential(\n",
    "            nn.Linear(num_cubes * 64, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, num_cubes))\n",
    "\n",
    "        self.num_cubes = num_cubes\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        # x.shape[b, 1, 72, 110, 110]\n",
    "        x_rearrange = rearrange(x, 'b c h w f -> b c f h w')\n",
    "        # x_rearrange.shape[b, 1, 72, 110, 110] to fit vit\n",
    "\n",
    "        logits = self.vit_encoder64(x_rearrange) # logits[b,64]\n",
    "        return logits\n",
    "\n",
    "    def forward(self, cubes):\n",
    "        # [B, 8, C, X, Y, Z]\n",
    "        cubes = cubes.transpose(0, 1)\n",
    "        # [8, B, C, X, Y, Z]\n",
    "        feats = []\n",
    "        for i in range(self.num_cubes):\n",
    "            output_fc6 = self.forward_once(cubes[i]) # output尺寸与输入一致\n",
    "            feats.append(output_fc6) # \n",
    "            ## hor_rot_logit: [B, 1]\n",
    "\n",
    "        feats = torch.cat(feats, 1) # feats[8, B, C, X, Y, Z]\n",
    "\n",
    "        # order_logits: [B, K]\n",
    "        order_logits = self.order_fc(feats)\n",
    "\n",
    "        # hor_rot_logits: [B*8, 1]\n",
    "        hor_rot_logits = self.sigmoid(self.hor_rot_fc(feats))\n",
    "        ver_rot_logits = self.sigmoid(self.ver_rot_fc(feats))\n",
    "        # mask\n",
    "        mask_logits = self.sigmoid(self.mask_fc(feats))\n",
    "\n",
    "        return order_logits, hor_rot_logits, ver_rot_logits, mask_logits\n",
    "\n",
    "    @staticmethod\n",
    "    def get_module_dicts():\n",
    "        encoder_layers = ['down_tr64', 'down_tr128', 'down_tr256', 'down_tr512']\n",
    "        fc_layers = ['fc6', 'order_fc', 'hor_rot_fc', 'ver_rot_fc']\n",
    "        module_dict = {'encoder': encoder_layers, 'fc':fc_layers}\n",
    "        return module_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "草稿测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 1, 110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "# 创建类的实例\n",
    "Vit_test = VIT3D_RKBP()\n",
    "\n",
    "# cubes[B, 8, C, X, Y, Z]\n",
    "b=2\n",
    "data = torch.randn([b, 8, 1, 110, 110, 72])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 100])\n",
      "tensor([[0.5016, 0.4935, 0.4386, 0.5066, 0.4757, 0.4933, 0.5227, 0.5233],\n",
      "        [0.5043, 0.4844, 0.4336, 0.4920, 0.4751, 0.4723, 0.5265, 0.5382]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([2, 8])\n",
      "tensor([[0.5105, 0.5606, 0.5270, 0.4956, 0.4892, 0.4640, 0.4621, 0.4769],\n",
      "        [0.5268, 0.5521, 0.5229, 0.4999, 0.4748, 0.4605, 0.4508, 0.4561]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([2, 8])\n",
      "tensor([[0.4690, 0.4631, 0.4723, 0.5256, 0.5147, 0.5237, 0.4695, 0.5019],\n",
      "        [0.4800, 0.4420, 0.4793, 0.5408, 0.4969, 0.5480, 0.4416, 0.5028]],\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "order_logits, hor_rot_logits, ver_rot_logits, mask_logits = Vit_test(data)\n",
    "print(order_logits.shape)\n",
    "print(hor_rot_logits)\n",
    "print(hor_rot_logits.shape)\n",
    "print(ver_rot_logits)\n",
    "print(ver_rot_logits.shape)\n",
    "print(mask_logits)\n",
    "print(mask_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试MRI图像重排列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 8, 1, 110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "b = 2\n",
    "all_cubes = torch.randn([b, 8, 1, 110, 110, 72])\n",
    "print(all_cubes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 110, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "all_cubes_list = []\n",
    "for i in range(all_cubes.shape[1]):\n",
    "    all_cubes_list.append(all_cubes[:,i,:,:,:,:])\n",
    "\n",
    "print(all_cubes_list[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 20, 110, 72])\n",
      "torch.Size([2, 1, 130, 110, 72])\n",
      "torch.Size([2, 1, 240, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "cube_jitter_xy=10\n",
    "cube_jitter_z=5\n",
    "jitter_xy = 2*10 \n",
    "jitter_xy_cube = torch.zeros(b, 1, jitter_xy, 110, 72)\n",
    "print(jitter_xy_cube.shape)\n",
    "test_tensor = torch.cat((all_cubes_list[0],jitter_xy_cube),dim=2)\n",
    "print(test_tensor.shape)\n",
    "test_tensor2 = torch.cat((test_tensor,all_cubes_list[1]),dim=2)\n",
    "print(test_tensor2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,8,2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 240, 110, 72])\n"
     ]
    }
   ],
   "source": [
    "cat_tensor_1 = []\n",
    "for i in range(0,8,2):\n",
    "    jitter_xy_cube = torch.zeros(b, 1, jitter_xy, 110, 72)\n",
    "    # print(jitter_xy_cube.shape)\n",
    "    test_tensor = torch.cat((all_cubes_list[i],jitter_xy_cube),dim=2)\n",
    "    # print(test_tensor.shape)\n",
    "    test_tensor2 = torch.cat((test_tensor,all_cubes_list[i+1]),dim=2)\n",
    "    # print(test_tensor2.shape)\n",
    "    cat_tensor_1.append(test_tensor2)\n",
    "\n",
    "print(cat_tensor_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 240, 240, 72])\n"
     ]
    }
   ],
   "source": [
    "cat_tensor_2 = []\n",
    "for i in range(0,4,2):\n",
    "    jitter_xy_cube = torch.zeros(b, 1, 240, jitter_xy, 72)\n",
    "    # print(jitter_xy_cube.shape)\n",
    "    test_tensor = torch.cat((cat_tensor_1[i],jitter_xy_cube),dim=3)\n",
    "    # print(test_tensor.shape)\n",
    "    test_tensor2 = torch.cat((test_tensor,cat_tensor_1[i+1]),dim=3)\n",
    "    # print(test_tensor2.shape)\n",
    "    cat_tensor_2.append(test_tensor2)\n",
    "\n",
    "print(cat_tensor_2[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 240, 20, 72])\n",
      "torch.Size([2, 1, 240, 240, 82])\n",
      "torch.Size([2, 1, 240, 240, 154])\n"
     ]
    }
   ],
   "source": [
    "jitter_z = 2*cube_jitter_z\n",
    "jitter_z_cube = torch.zeros(b, 1, 240, 240, jitter_z)\n",
    "print(jitter_xy_cube.shape)\n",
    "test_tensor = torch.cat((cat_tensor_2[0],jitter_z_cube),dim=4)\n",
    "print(test_tensor.shape)\n",
    "catted_tensor = torch.cat((test_tensor,cat_tensor_2[1]),dim=4)\n",
    "print(catted_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 220, 220, 72])\n"
     ]
    }
   ],
   "source": [
    "test_tensor_sq = torch.cat((test_tensor, test_tensor2),dim=3)\n",
    "print(test_tensor_sq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bak_to_onecube(all_cubes,cube_jitter_xy=10,cube_jitter_z=5):\n",
    "    all_cubes_list = []\n",
    "    for i in range(all_cubes.shape[0]):\n",
    "        all_cubes_list.append(all_cubes[i,:,:,:,:])\n",
    "    jitter_xy = 2*cube_jitter_xy\n",
    "    jitter_z = 2*cube_jitter_z\n",
    "    cat_tensor_1 = []\n",
    "    for i in range(0,8,2):\n",
    "        jitter_xy_cube = torch.zeros(1, jitter_xy, 110, 72)\n",
    "        # print(jitter_xy_cube.shape)\n",
    "        test_tensor = torch.cat((all_cubes_list[i],jitter_xy_cube),dim=1)\n",
    "        # print(test_tensor.shape)\n",
    "        test_tensor2 = torch.cat((test_tensor,all_cubes_list[i+1]),dim=1)\n",
    "        # print(test_tensor2.shape)\n",
    "        cat_tensor_1.append(test_tensor2)\n",
    "    cat_tensor_2 = []\n",
    "    for i in range(0,4,2):\n",
    "        jitter_xy_cube = torch.zeros(1, 240, jitter_xy, 72)\n",
    "        # print(jitter_xy_cube.shape)\n",
    "        test_tensor = torch.cat((cat_tensor_1[i],jitter_xy_cube),dim=2)\n",
    "        # print(test_tensor.shape)\n",
    "        test_tensor2 = torch.cat((test_tensor,cat_tensor_1[i+1]),dim=2)\n",
    "        # print(test_tensor2.shape)\n",
    "        cat_tensor_2.append(test_tensor2)\n",
    "    jitter_z = 2*cube_jitter_z\n",
    "    jitter_z_cube = torch.zeros(1, 240, 240, jitter_z)\n",
    "    # print(jitter_xy_cube.shape)\n",
    "    test_tensor = torch.cat((cat_tensor_2[0],jitter_z_cube),dim=3)\n",
    "    # print(test_tensor.shape)\n",
    "    catted_tensor = torch.cat((test_tensor,cat_tensor_2[1]),dim=3)\n",
    "    # print(catted_tensor.shape)\n",
    "    return catted_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 110, 110, 72])\n",
      "torch.Size([1, 240, 240, 154])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "all_cubes = torch.randn([8, 1, 110, 110, 72])\n",
    "print(all_cubes.shape)\n",
    "catted_tensor = bak_to_onecube(all_cubes)\n",
    "print(catted_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_3d(self, image, flag, crop_size): # ...（对图像执行3D裁剪的方法）\n",
    "    h, w, d = crop_size[0], crop_size[1], crop_size[2]\n",
    "    h_old, w_old, d_old = image.shape[0], image.shape[1], image.shape[2]\n",
    "\n",
    "    if flag == 'train': #如果 flag 是 'train'，则进行随机裁剪。在这种情况下，生成随机的裁剪起始点 (x, y, z)，h_old-h是为了确保裁剪框不超出图像边界。\n",
    "        # crop random\n",
    "        x = np.random.randint(0, 1 + h_old - h) #返回一个随机数或随机数数组(指定size时)\n",
    "        y = np.random.randint(0, 1 + w_old - w)\n",
    "        z = np.random.randint(0, 1 + d_old - d)\n",
    "    else: #如果 flag 不是 'train'，则进行中心裁剪。计算裁剪起始点 (x, y, z) 使得裁剪的区域在图像中居中。\n",
    "        # crop center\n",
    "        x = int((h_old - h) / 2)\n",
    "        y = int((w_old - w) / 2)\n",
    "        z = int((d_old - d) / 2)\n",
    "\n",
    "    return self.do_crop_3d(image, x, y, z, h, w, d)\n",
    "\n",
    "def do_crop_3d(self, image, x, y, z, h, w, d): # 3D裁剪的辅助函数，确保整数和返回对应位置的3D块\n",
    "    assert type(x) == int, x\n",
    "    assert type(y) == int, y\n",
    "    assert type(z) == int, z\n",
    "    assert type(h) == int, h\n",
    "    assert type(w) == int, w\n",
    "    assert type(d) == int, d\n",
    "\n",
    "    return image[x:x + h, y:y + w, z:z + d] #这边取的时最边界点加上crop_size的大小，解释了为何上述代码的定中心方式如此\n",
    "\n",
    "def crop_cubes_3d(self, image, flag, cubes_per_side, cube_jitter_xy=3, cube_jitter_z=3): #在3D图像中裁剪多个3D立方体的方法，jitter貌似是为了防止数据连续变化留出的间隔大小，从代码里可以看出如果有jitter则再次进行3D裁切，cubes_per_side应该是每个方向有多少个cube\n",
    "    h, w, d = image.shape\n",
    "\n",
    "    patch_overlap = -cube_jitter_xy if cube_jitter_xy < 0 else 0 #patch_overlap 计算了在裁剪时可能存在的重叠区域。如果 cube_jitter_xy 是负数，则 patch_overlap 采用该值；否则，为零。\n",
    "\n",
    "    #h_grid、w_grid 和 d_grid 计算了每个立方体的网格大小，以确保裁剪时没有重叠区域。\n",
    "    # 这里主要思想应该是把切出来的3D大块划分为各个小块,这里拿笔记做做数学题吧，好久没写了。\n",
    "    h_grid = (h - patch_overlap) // cubes_per_side\n",
    "    w_grid = (w - patch_overlap) // cubes_per_side\n",
    "    d_grid = (d - patch_overlap) // cubes_per_side\n",
    "    h_patch = h_grid - cube_jitter_xy\n",
    "    w_patch = w_grid - cube_jitter_xy\n",
    "    d_patch = d_grid - cube_jitter_z\n",
    "\n",
    "    cubes = []\n",
    "    for i in range(cubes_per_side):\n",
    "        for j in range(cubes_per_side):\n",
    "            for k in range(cubes_per_side):\n",
    "\n",
    "                p = self.do_crop_3d(image, #当i=0时，从0截取到第一个grid\n",
    "                                i * h_grid,\n",
    "                                j * w_grid,\n",
    "                                k * d_grid,\n",
    "                                h_grid + patch_overlap,\n",
    "                                w_grid + patch_overlap,\n",
    "                                d_grid + patch_overlap)\n",
    "\n",
    "                if h_patch < h_grid or w_patch < w_grid or d_patch < d_grid: #如果有jitter，则对之前裁切好的3D块再次裁切以保留jitter大小的间隔\n",
    "                    p = self.crop_3d(p, flag, [h_patch, w_patch, d_patch])\n",
    "\n",
    "                cubes.append(p)\n",
    "\n",
    "    return cubes\n",
    "\n",
    "def rearrange(self, cubes, K_permutations):  # ...根据排列重新排列立方体的方法\n",
    "    label = random.randint(0, len(K_permutations) - 1)\n",
    "    # print('label', np.array(K_permutations[label]), label)\n",
    "    # print(cubes[np.array(K_permutations[label])])\n",
    "    return np.array(cubes)[np.array(K_permutations[label])], label\n",
    "\n",
    "def center_crop_xy(self, image, size): # 在image中间截一个size大小的缺口，画图很容易理解\n",
    "    \"\"\"CenterCrop a sample.\n",
    "        Args:\n",
    "            image: [D, H, W]\n",
    "            label:[D, H, W]\n",
    "            crop_size: the desired output size in the x-y plane\n",
    "        Returns:\n",
    "            out_image:[D, h, w]\n",
    "            out_label:[D, h, w]\n",
    "    \"\"\"\n",
    "    h, w, d = image.shape\n",
    "\n",
    "    h1 = int(round((h - size[0]) / 2.)) #round() 函数将结果四舍五入为最接近的整数，确保裁剪区域的起始点是整数。\n",
    "    w1 = int(round((w - size[1]) / 2.))\n",
    "\n",
    "    image = image[h1:h1 + size[0], w1:w1 + size[1], :]\n",
    "    return image\n",
    "\n",
    "def rotate(self, cubes): # ...（旋转3D立方体的方法）\n",
    "\n",
    "    # multi-hot labels\n",
    "    # [8, H, W, D]\n",
    "    rot_cubes = copy.deepcopy(cubes) # 创建输入立方体的深层副本，以免修改原始数据\n",
    "    hor_vector = [] # 记录水平旋转的向量\n",
    "    ver_vector = [] # 记录垂直旋转的向量\n",
    "\n",
    "    for i in range(self.num_cubes):\n",
    "        p = random.random()  # 生成一个0到1之间的随机数\n",
    "        cube = rot_cubes[i] # 获取当前处理的立方体,这里debug看cube是个tensor，后续会出bug\n",
    "        # cube_ = cube.numpy() #设置一个numpy_arrary防止np.flip bug, 如果输入是nparray就不用这步\n",
    "        # p = 0.1 # for test\n",
    "        # [H, W, D]\n",
    "        if p < 1/3: # 如果 p 小于 1/3，表示进行水平旋转。将水平旋转的标志添加到 hor_vector，并沿x轴翻转180度。\n",
    "            hor_vector.append(1)\n",
    "            ver_vector.append(0)\n",
    "            # rotate 180 along x axis\n",
    "            rot_cubes[i] = np.flip(cube, (1, 2)) # 沿x轴翻转180度,BUG ValueError: step must be greater than zero,最后输出的应该是numpy形式\n",
    "            # cube = np.flip(cube_, (1, 2))\n",
    "            # rot_cubes[i] = cube\n",
    "        elif p < 2/3: #如果 p 大于等于 1/3 且小于 2/3，表示进行垂直旋转。将垂直旋转的标志添加到 ver_vector，并沿z轴翻转180度。\n",
    "            hor_vector.append(0)\n",
    "            ver_vector.append(1)\n",
    "            # rotate 180 along z axis\n",
    "            rot_cubes[i] = np.flip(cube, (0, 1)) # 沿z轴翻转180度\n",
    "            # cube = np.flip(cube_, (0, 1))\n",
    "            # rot_cubes[i] = cube\n",
    "\n",
    "        else: #如果 p 大于等于 2/3，不进行旋转，标志都设为0。\n",
    "            hor_vector.append(0)\n",
    "            ver_vector.append(0)\n",
    "\n",
    "    return rot_cubes, hor_vector, ver_vector\n",
    "\n",
    "def mask(self, cubes): # ...（对3D立方体应用掩码的方法）\n",
    "    mask_vector = []\n",
    "    masked_cubes = copy.deepcopy(cubes) # 创建一个输入立方体的深层副本，以免修改原始数据\n",
    "    for i in range(self.num_cubes):\n",
    "        cube = masked_cubes[i] # 获取当前处理的立方体\n",
    "        if random.random() < 0.5: # 如果随机数小于0.5，应用掩码\n",
    "            # mask\n",
    "            mask_vector.append(1) # 记录掩码的标志为1\n",
    "            R = np.random.uniform(0, 1, cube.shape) # 生成与立方体相同形状的随机数矩阵\n",
    "            R = (R > 0.5).astype(np.int32) # 将大于0.5的值设置为1，否则为0，形成二值掩码\n",
    "            masked_cubes[i] = cube * R # 将立方体与二值掩码相乘，进行掩码操作\n",
    "        else:\n",
    "            mask_vector.append(0) # 如果随机数大于等于0.5，不应用掩码，标志为0\n",
    "\n",
    "    return masked_cubes, mask_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试simpleVIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input为[b, 1, 240, 240, 154]\n",
    "\n",
    "from vit_pytorch import SimpleViT\n",
    "import torch\n",
    "\n",
    "all_cubes = torch.randn([4, 1, 240, 240, 154])\n",
    "vit = SimpleViT(image_size = 240,patch_size = 120,num_classes = 1024,dim = 1024,depth = 1,heads = 1,mlp_dim = 2048,channels = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "EinopsError",
     "evalue": "Expected 4 dimensions, got 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEinopsError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_100516\\2528450837.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_cubes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\vit_pytorch\\simple_vit.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_patch_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_embedding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\einops\\layers\\torch.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mRearrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRearrangeMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mapply_for_scriptable_torch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rearrange'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply_recipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\einops\\_torch_specific.py\u001b[0m in \u001b[0;36mapply_for_scriptable_torch\u001b[1;34m(recipe, tensor, reduction_type)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTorchJitBackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0minit_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes_reordering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madded_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_shapes\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0m_reconstruct_from_shape_uncached\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_axes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Programming\\anaconda3\\envs\\Medic_ssl\\lib\\site-packages\\einops\\einops.py\u001b[0m in \u001b[0;36m_reconstruct_from_shape_uncached\u001b[1;34m(self, shape)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mEinopsError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected {} dimensions, got {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_composite_axes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mellipsis_shape\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEinopsError\u001b[0m: Expected 4 dimensions, got 5"
     ]
    }
   ],
   "source": [
    "output = vit(all_cubes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
